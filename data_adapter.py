#!/usr/bin/env python3
"""æ•°æ®é€‚é…å™¨ï¼šæœºå™¨äººæ•°æ®ä¸å­¦ä¹ æ•°æ®æ ¼å¼è½¬æ¢å™¨.

è¯¥æ¨¡å—æä¾›HIROLRobotPlatformæœºå™¨äººæ•°æ®æ ¼å¼ä¸å­¦ä¹ ç®—æ³•æ•°æ®æ ¼å¼ä¹‹é—´çš„è½¬æ¢åŠŸèƒ½ã€‚
æ”¯æŒå¤šç§æœºå™¨äººå¹³å°å’Œç›¸æœºé…ç½®çš„æ•°æ®é€‚é…ã€‚
"""

import numpy as np
import torch
from typing import Dict, List, Optional, Union, Any
import cv2

import glog as log
from hardware.base.utils import RobotJointState


class RobotDataAdapter:
    """æœºå™¨äººæ•°æ®ä¸å­¦ä¹ æ•°æ®æ ¼å¼è½¬æ¢å™¨.
    
    æä¾›HIROLRobotPlatformä¸å­¦ä¹ ç®—æ³•ä¹‹é—´çš„æ•°æ®æ ¼å¼è½¬æ¢åŠŸèƒ½ï¼Œ
    åŒ…æ‹¬å…³èŠ‚çŠ¶æ€ã€ç›¸æœºæ•°æ®å’ŒåŠ¨ä½œæŒ‡ä»¤çš„åŒå‘è½¬æ¢ã€‚
    """
    
    def __init__(self, robot_type: str = "generic"):
        """åˆå§‹åŒ–æ•°æ®é€‚é…å™¨.
        
        Args:
            robot_type: æœºå™¨äººç±»å‹ï¼Œç”¨äºç‰¹å®šçš„æ•°æ®æ ¼å¼é€‚é…
        """
        self.robot_type = robot_type
        log.info(f"âœ… æ•°æ®é€‚é…å™¨åˆå§‹åŒ–: {robot_type}")
    
    @staticmethod
    def robot_state_to_numpy(joint_state: RobotJointState) -> np.ndarray:
        """å°†RobotJointStateè½¬æ¢ä¸ºnumpyæ•°ç»„.
        
        Args:
            joint_state: HIROLRobotPlatformçš„å…³èŠ‚çŠ¶æ€å¯¹è±¡
            
        Returns:
            np.ndarray: å…³èŠ‚ä½ç½®çš„numpyæ•°ç»„
            
        Raises:
            ValueError: å½“å…³èŠ‚çŠ¶æ€æ•°æ®æ— æ•ˆæ—¶æŠ›å‡º
        """
        if joint_state._positions is None:
            raise ValueError("å…³èŠ‚ä½ç½®æ•°æ®ä¸ºç©º")
        
        if isinstance(joint_state._positions, (list, tuple)):
            positions = np.array(joint_state._positions, dtype=np.float32)
        elif isinstance(joint_state._positions, np.ndarray):
            positions = joint_state._positions.astype(np.float32)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å…³èŠ‚ä½ç½®æ•°æ®ç±»å‹: {type(joint_state._positions)}")
        
        log.debug(f"å…³èŠ‚çŠ¶æ€è½¬æ¢: {positions.shape} -> numpyæ•°ç»„")
        return positions
    
    @staticmethod
    def numpy_to_robot_actions(actions: np.ndarray) -> List[float]:
        """å°†numpyåŠ¨ä½œæ•°ç»„è½¬æ¢ä¸ºæœºå™¨äººå…³èŠ‚æŒ‡ä»¤.
        
        Args:
            actions: å­¦ä¹ ç®—æ³•è¾“å‡ºçš„åŠ¨ä½œæ•°ç»„
            
        Returns:
            List[float]: æœºå™¨äººå…³èŠ‚æŒ‡ä»¤åˆ—è¡¨
            
        Raises:
            ValueError: å½“åŠ¨ä½œæ•°æ®æ ¼å¼æ— æ•ˆæ—¶æŠ›å‡º
        """
        if not isinstance(actions, np.ndarray):
            raise ValueError(f"åŠ¨ä½œæ•°æ®å¿…é¡»æ˜¯numpyæ•°ç»„ï¼Œå½“å‰ç±»å‹: {type(actions)}")
        
        # ç¡®ä¿æ•°æ®æ˜¯ä¸€ç»´çš„
        if actions.ndim > 1:
            if actions.shape[0] == 1:
                actions = actions.squeeze(0)
            else:
                # å¦‚æœæ˜¯åŠ¨ä½œåºåˆ—ï¼Œå–ç¬¬ä¸€ä¸ªåŠ¨ä½œ
                actions = actions[0]
                log.warning(f"âš ï¸ æ£€æµ‹åˆ°åŠ¨ä½œåºåˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåŠ¨ä½œ: {actions.shape}")
        
        # è½¬æ¢ä¸ºPythonæµ®ç‚¹æ•°åˆ—è¡¨
        action_list = actions.astype(float).tolist()
        
        log.debug(f"åŠ¨ä½œè½¬æ¢: {len(action_list)}ä¸ªå…³èŠ‚æŒ‡ä»¤")
        return action_list
    
    @staticmethod
    def camera_dict_to_tensor(
        camera_data: Dict[str, np.ndarray], 
        normalize: bool = True,
        target_size: Optional[tuple] = None
    ) -> torch.Tensor:
        """å°†ç›¸æœºæ•°æ®å­—å…¸è½¬æ¢ä¸ºtensor.
        
        Args:
            camera_data: ç›¸æœºåç§°åˆ°å›¾åƒæ•°æ®çš„æ˜ å°„
            normalize: æ˜¯å¦è¿›è¡ŒImageNetå½’ä¸€åŒ–
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸ (height, width)
            
        Returns:
            torch.Tensor: å½¢çŠ¶ä¸º(batch, num_cameras, channels, height, width)çš„tensor
            
        Raises:
            ValueError: å½“ç›¸æœºæ•°æ®æ ¼å¼æ— æ•ˆæ—¶æŠ›å‡º
        """
        if not camera_data:
            raise ValueError("ç›¸æœºæ•°æ®ä¸ºç©º")
        
        # æŒ‰ç›¸æœºåç§°æ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
        camera_names = sorted(camera_data.keys())
        processed_images = []
        
        for cam_name in camera_names:
            image = camera_data[cam_name]
            
            # éªŒè¯å›¾åƒæ•°æ®
            if not isinstance(image, np.ndarray):
                raise ValueError(f"ç›¸æœº {cam_name} æ•°æ®å¿…é¡»æ˜¯numpyæ•°ç»„")
            
            # å¤„ç†å›¾åƒå°ºå¯¸
            if target_size is not None:
                if image.shape[:2] != target_size:
                    image = cv2.resize(image, (target_size[1], target_size[0]))
                    log.debug(f"ç›¸æœº {cam_name} å›¾åƒè°ƒæ•´è‡³: {target_size}")
            
            # è½¬æ¢ä¸ºfloatå¹¶å½’ä¸€åŒ–åˆ°[0,1]
            if image.dtype == np.uint8:
                image = image.astype(np.float32) / 255.0
            
            # ç¡®ä¿RGBé€šé“é¡ºåº (H, W, C)
            if len(image.shape) == 3 and image.shape[2] == 3:
                # è½¬æ¢ä¸º (C, H, W)
                image = np.transpose(image, (2, 0, 1))
            else:
                raise ValueError(f"ç›¸æœº {cam_name} å›¾åƒå¿…é¡»æ˜¯3é€šé“RGBæ ¼å¼")
            
            processed_images.append(image)
        
        # å †å ä¸º (num_cameras, C, H, W)
        images_array = np.stack(processed_images, axis=0)
        
        # è½¬æ¢ä¸ºtensor
        images_tensor = torch.from_numpy(images_array).float()
        
        # ImageNetå½’ä¸€åŒ–
        if normalize:
            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
            images_tensor = (images_tensor - mean) / std
        
        # æ·»åŠ batchç»´åº¦: (1, num_cameras, C, H, W)
        images_tensor = images_tensor.unsqueeze(0)
        
        log.debug(f"ç›¸æœºæ•°æ®è½¬æ¢: {len(camera_names)}ä¸ªç›¸æœº -> {images_tensor.shape}")
        return images_tensor
    
    def validate_robot_state(self, joint_state: RobotJointState) -> bool:
        """éªŒè¯æœºå™¨äººçŠ¶æ€æ•°æ®çš„æœ‰æ•ˆæ€§.
        
        Args:
            joint_state: æœºå™¨äººå…³èŠ‚çŠ¶æ€
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        if joint_state._positions is None:
            log.error("âŒ å…³èŠ‚ä½ç½®æ•°æ®ä¸ºç©º")
            return False
        
        try:
            positions = self.robot_state_to_numpy(joint_state)
            if len(positions) == 0:
                log.error("âŒ å…³èŠ‚ä½ç½®æ•°ç»„ä¸ºç©º")
                return False
            
            # æ£€æŸ¥æ•°å€¼æ˜¯å¦æœ‰æ•ˆ
            if np.any(np.isnan(positions)) or np.any(np.isinf(positions)):
                log.error("âŒ å…³èŠ‚ä½ç½®åŒ…å«æ— æ•ˆæ•°å€¼")
                return False
                
            return True
        except Exception as e:
            log.error(f"âŒ æœºå™¨äººçŠ¶æ€éªŒè¯å¤±è´¥: {str(e)}")
            return False
    
    def validate_camera_data(self, camera_data: Dict[str, np.ndarray]) -> bool:
        """éªŒè¯ç›¸æœºæ•°æ®çš„æœ‰æ•ˆæ€§.
        
        Args:
            camera_data: ç›¸æœºæ•°æ®å­—å…¸
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        if not camera_data:
            log.error("âŒ ç›¸æœºæ•°æ®ä¸ºç©º")
            return False
        
        for cam_name, image in camera_data.items():
            if not isinstance(image, np.ndarray):
                log.error(f"âŒ ç›¸æœº {cam_name} æ•°æ®ç±»å‹é”™è¯¯")
                return False
            
            if len(image.shape) != 3 or image.shape[2] != 3:
                log.error(f"âŒ ç›¸æœº {cam_name} å›¾åƒæ ¼å¼é”™è¯¯: {image.shape}")
                return False
        
        return True


class FR3DataAdapter(RobotDataAdapter):
    """FR3æœºå™¨äººä¸“ç”¨æ•°æ®é€‚é…å™¨."""
    
    def __init__(self):
        super().__init__("fr3")
        self.expected_dof = 7  # FR3æœºå™¨äºº7è‡ªç”±åº¦
    
    def validate_robot_state(self, joint_state: RobotJointState) -> bool:
        """FR3ç‰¹å®šçš„çŠ¶æ€éªŒè¯."""
        if not super().validate_robot_state(joint_state):
            return False
        
        positions = self.robot_state_to_numpy(joint_state)
        if len(positions) != self.expected_dof:
            log.error(f"âŒ FR3å…³èŠ‚æ•°é‡é”™è¯¯: æœŸæœ›{self.expected_dof}, å®é™…{len(positions)}")
            return False
        
        return True


class Monte01DataAdapter(RobotDataAdapter):
    """Monte01åŒè‡‚æœºå™¨äººä¸“ç”¨æ•°æ®é€‚é…å™¨ (16 DOF)."""
    
    def __init__(self):
        super().__init__("monte01")
        self.expected_dof = 16  # Monte01åŒè‡‚: (7+1) Ã— 2 = 16è‡ªç”±åº¦
        self.left_arm_indices = slice(0, 8)   # å·¦è‡‚: 0-7 (7å…³èŠ‚+1å¤¹çˆª)
        self.right_arm_indices = slice(8, 16) # å³è‡‚: 8-15 (7å…³èŠ‚+1å¤¹çˆª)
        self.gripper_range = (0.0, 0.074)    # Monte01å¤¹çˆªèŒƒå›´(ç±³)
        
        # å¯¼å…¥åæ ‡ç³»è½¬æ¢å‡½æ•°
        try:
            from hardware.monte01.coordinate_transforms import dual_arm_corenetic_to_xarm, dual_arm_xarm_to_corenetic
            self.corenetic_to_xarm = dual_arm_corenetic_to_xarm
            self.xarm_to_corenetic = dual_arm_xarm_to_corenetic
            self.coordinate_transform_enabled = True
            log.info(f"âœ… Monte01åŒè‡‚æ•°æ®é€‚é…å™¨åˆå§‹åŒ– (16 DOF, åæ ‡ç³»è½¬æ¢å·²å¯ç”¨)")
        except ImportError as e:
            log.warning(f"âš ï¸ åæ ‡ç³»è½¬æ¢æ¨¡å—å¯¼å…¥å¤±è´¥: {e}, å°†ç¦ç”¨åæ ‡ç³»è½¬æ¢")
            self.coordinate_transform_enabled = False
            log.info(f"âœ… Monte01åŒè‡‚æ•°æ®é€‚é…å™¨åˆå§‹åŒ– (16 DOF, åæ ‡ç³»è½¬æ¢å·²ç¦ç”¨)")
    
    def validate_robot_state(self, joint_state: RobotJointState) -> bool:
        """Monte01åŒè‡‚çŠ¶æ€éªŒè¯."""
        if not super().validate_robot_state(joint_state):
            return False
        
        positions = self.robot_state_to_numpy(joint_state)
        
        # éªŒè¯è½¬æ¢åçš„ç»´åº¦
        if len(positions) != self.expected_dof:
            log.error(f"âŒ Monte01å…³èŠ‚æ•°é‡é”™è¯¯: æœŸæœ›{self.expected_dof}, å®é™…{len(positions)}")
            return False
        
        # éªŒè¯åŒè‡‚çŠ¶æ€åˆç†æ€§ï¼ˆä½¿ç”¨16ç»´æ•°æ®ï¼‰
        left_state, right_state = self.split_dual_arm_state(positions)
        
        # éªŒè¯å·¦è‡‚çŠ¶æ€
        if not self._validate_single_arm_state(left_state, "å·¦è‡‚"):
            return False
            
        # éªŒè¯å³è‡‚çŠ¶æ€
        if not self._validate_single_arm_state(right_state, "å³è‡‚"):
            return False
        
        return True
    
    def robot_state_to_numpy(self, joint_state: RobotJointState) -> np.ndarray:
        """Monte01ä¸“ç”¨ï¼šå°†RobotJointStateè½¬æ¢ä¸ºnumpyæ•°ç»„.
        
        å…³é”®ä¿®å¤ï¼šä¿æŒCORENETICåæ ‡ç³»ç”¨äºæ¨¡å‹è¾“å…¥ï¼Œç¡®ä¿ä¸è®­ç»ƒæ•°æ®ä¸€è‡´
        æ¨ç†å¼•æ“å·²åœ¨_get_monte01_dual_arm_state()ä¸­å¤„ç†äº†14ç»´->16ç»´è½¬æ¢
        
        Args:
            joint_state: HIROLRobotPlatformçš„å…³èŠ‚çŠ¶æ€å¯¹è±¡
            
        Returns:
            np.ndarray: CORENETICåæ ‡ç³»çš„å…³èŠ‚ä½ç½®æ•°ç»„ (ç”¨äºACTæ¨¡å‹è¾“å…¥)
        """
        # ä½¿ç”¨çˆ¶ç±»æ–¹æ³•è·å–CORENETICåæ ‡ç³»çš„ä½ç½®
        corenetic_positions = super().robot_state_to_numpy(joint_state)
        
        # å…³é”®ä¿®å¤ï¼šä¿æŒCORENETICåæ ‡ç³»ä¸è½¬æ¢ï¼Œç¡®ä¿ä¸è®­ç»ƒæ•°æ®ä¸€è‡´
        log.debug(f"ğŸ’¡ çŠ¶æ€ä¿æŒCORENETICåæ ‡ç³»ç”¨äºæ¨¡å‹è¾“å…¥: å·¦è‡‚{corenetic_positions[:7].round(3)}, å³è‡‚{corenetic_positions[8:15].round(3)}")
        return corenetic_positions  # ç›´æ¥è¿”å›CORENETICåæ ‡ç³»çŠ¶æ€
    
    def split_dual_arm_state(self, state: np.ndarray) -> tuple:
        """åˆ†ç¦»åŒè‡‚çŠ¶æ€.
        
        Args:
            state: 16ç»´åŒè‡‚çŠ¶æ€
            
        Returns:
            tuple: (å·¦è‡‚8ç»´çŠ¶æ€, å³è‡‚8ç»´çŠ¶æ€)
        """
        if len(state) != self.expected_dof:
            raise ValueError(f"çŠ¶æ€ç»´åº¦é”™è¯¯: æœŸæœ›{self.expected_dof}, å®é™…{len(state)}")
        
        left_state = state[self.left_arm_indices]
        right_state = state[self.right_arm_indices]
        
        return left_state, right_state
    
    def action_to_robot_command(self, action: np.ndarray) -> np.ndarray:
        """å°†æ¨¡å‹è¾“å‡ºçš„åŠ¨ä½œè½¬æ¢ä¸ºæœºå™¨äººå‘½ä»¤.
        
        æ¨¡å‹è¾“å‡ºçš„æ˜¯CORENETICåæ ‡ç³»çš„åŠ¨ä½œï¼Œéœ€è¦è½¬æ¢ä¸ºXARMåæ ‡ç³»ã€‚
        è½¬æ¢åçš„XARMåŠ¨ä½œå°†ç›´æ¥è¢«xarm7_arm.pyè½¬æ¢å›XARMç¡¬ä»¶æ ¼å¼æ‰§è¡Œã€‚
        
        Args:
            action: CORENETICåæ ‡ç³»çš„16ç»´åŠ¨ä½œ (æ¨¡å‹è¾“å‡º)
            
        Returns:
            XARMåæ ‡ç³»çš„16ç»´æœºå™¨äººå‘½ä»¤ (ç»™xarm7_arm.py)
        """
        if len(action) != self.expected_dof:
            raise ValueError(f"åŠ¨ä½œç»´åº¦é”™è¯¯: æœŸæœ›{self.expected_dof}, å®é™…{len(action)}")
        
        return action
    
    def combine_dual_arm_state(self, left_state: np.ndarray, right_state: np.ndarray) -> np.ndarray:
        """ç»„åˆåŒè‡‚çŠ¶æ€.
        
        Args:
            left_state: å·¦è‡‚8ç»´çŠ¶æ€
            right_state: å³è‡‚8ç»´çŠ¶æ€
            
        Returns:
            np.ndarray: 16ç»´åŒè‡‚çŠ¶æ€
        """
        if len(left_state) != 8 or len(right_state) != 8:
            raise ValueError(f"å•è‡‚çŠ¶æ€ç»´åº¦é”™è¯¯: å·¦è‡‚{len(left_state)}, å³è‡‚{len(right_state)}, éƒ½åº”ä¸º8ç»´")
        
        return np.concatenate([left_state, right_state])
    
    def _validate_single_arm_state(self, arm_state: np.ndarray, arm_name: str) -> bool:
        """éªŒè¯å•ä¸ªæ‰‹è‡‚çŠ¶æ€."""
        if len(arm_state) != 8:
            log.error(f"âŒ {arm_name}çŠ¶æ€ç»´åº¦é”™è¯¯: æœŸæœ›8, å®é™…{len(arm_state)}")
            return False
        
        
        # éªŒè¯å¤¹çˆªä½ç½®èŒƒå›´
        gripper_position = arm_state[7]
        if not (self.gripper_range[0] <= gripper_position <= self.gripper_range[1]):
            log.warning(f"âš ï¸ {arm_name}å¤¹çˆªä½ç½®è¶…å‡ºèŒƒå›´ {self.gripper_range}: {gripper_position}")
        
        return True
    
    def validate_camera_data(self, camera_data: Dict[str, np.ndarray]) -> bool:
        """Monte01ä¸‰ç›¸æœºæ•°æ®éªŒè¯."""
        expected_cameras = ['left_ee_cam', 'right_ee_cam', 'third_person_cam']
        
        # åŸºæœ¬ç›¸æœºéªŒè¯
        if not super().validate_camera_data(camera_data):
            return False
        
        # æ£€æŸ¥Monte01ç‰¹å®šçš„ç›¸æœºé…ç½®
        missing_cameras = [cam for cam in expected_cameras if cam not in camera_data]
        if missing_cameras:
            log.warning(f"âš ï¸ Monte01ç¼ºå°‘ç›¸æœº: {missing_cameras}")
        
        return True


def create_data_adapter(robot_type: str) -> RobotDataAdapter:
    """æ•°æ®é€‚é…å™¨å·¥å‚å‡½æ•°.
    
    Args:
        robot_type: æœºå™¨äººç±»å‹
        
    Returns:
        RobotDataAdapter: å¯¹åº”çš„æ•°æ®é€‚é…å™¨å®ä¾‹
        
    Raises:
        ValueError: å½“æœºå™¨äººç±»å‹ä¸æ”¯æŒæ—¶æŠ›å‡º
    """
    adapters = {
        "fr3": FR3DataAdapter,
        "monte01": Monte01DataAdapter,
        "generic": RobotDataAdapter,
    }
    
    if robot_type not in adapters:
        raise ValueError(f"ä¸æ”¯æŒçš„æœºå™¨äººç±»å‹: {robot_type}")
    
    return adapters[robot_type]()