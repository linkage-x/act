#!/usr/bin/env python3

import numpy as np
import cv2
import time
from inference_fr3 import FR3ACTInference

class FR3RealtimeController:
    """FR3å®æ—¶æ§åˆ¶å™¨"""
    
    def __init__(self, ckpt_dir, task_name='fr3_peg_in_hole_extended'):
        self.inferencer = FR3ACTInference(ckpt_dir, task_name)
        self.action_buffer = None  # åŠ¨ä½œç¼“å†²åŒº
        self.buffer_index = 0      # å½“å‰åŠ¨ä½œç´¢å¼•
        
        print("ğŸ¤– FR3å®æ—¶æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def get_robot_state(self):
        """
        è·å–æœºå™¨äººå½“å‰çŠ¶æ€ (éœ€è¦æ ¹æ®å®é™…æœºå™¨äººæ¥å£å®ç°)
        
        Returns:
            qpos: 8ç»´å…³èŠ‚ä½ç½® [7 arm joints + 1 gripper]
        """
        # TODO: å®ç°å®é™…çš„æœºå™¨äººçŠ¶æ€è¯»å–
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        qpos = np.array([0.0, -0.5, 0.3, 0.0, -0.2, 0.1, 0.0, 0.05])
        return qpos
        
    def get_camera_images(self):
        """
        è·å–ç›¸æœºå›¾åƒ (éœ€è¦æ ¹æ®å®é™…ç›¸æœºæ¥å£å®ç°)
        
        Returns:
            images_dict: {'ee_cam': img, 'third_person_cam': img}
        """
        # TODO: å®ç°å®é™…çš„ç›¸æœºå›¾åƒè·å–
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        ee_img = np.random.rand(480, 640, 3).astype(np.uint8) * 255
        third_person_img = np.random.rand(480, 640, 3).astype(np.uint8) * 255
        
        return {
            'ee_cam': ee_img,
            'third_person_cam': third_person_img
        }
        
    def send_action_to_robot(self, action):
        """
        å‘é€åŠ¨ä½œåˆ°æœºå™¨äºº (éœ€è¦æ ¹æ®å®é™…æœºå™¨äººæ¥å£å®ç°)
        
        Args:
            action: 8ç»´åŠ¨ä½œ [7 arm joints + 1 gripper]
        """
        # TODO: å®ç°å®é™…çš„æœºå™¨äººæ§åˆ¶
        print(f"å‘é€åŠ¨ä½œ: {action}")
        
    def predict_action_sequence(self, qpos, images_dict):
        """é¢„æµ‹åŠ¨ä½œåºåˆ—å¹¶æ›´æ–°ç¼“å†²åŒº"""
        action_sequence = self.inferencer.predict(qpos, images_dict)
        self.action_buffer = action_sequence
        self.buffer_index = 0
        return action_sequence
        
    def get_next_action(self):
        """ä»ç¼“å†²åŒºè·å–ä¸‹ä¸€ä¸ªåŠ¨ä½œ"""
        if self.action_buffer is None or self.buffer_index >= len(self.action_buffer):
            return None
            
        action = self.action_buffer[self.buffer_index]
        self.buffer_index += 1
        return action
        
    def run_control_loop(self, duration=30, control_frequency=10):
        """
        è¿è¡Œæ§åˆ¶å¾ªç¯
        
        Args:
            duration: è¿è¡Œæ—¶é•¿ (ç§’)
            control_frequency: æ§åˆ¶é¢‘ç‡ (Hz)
        """
        print(f"ğŸš€ å¼€å§‹æ§åˆ¶å¾ªç¯ - æ—¶é•¿:{duration}s, é¢‘ç‡:{control_frequency}Hz")
        
        dt = 1.0 / control_frequency
        start_time = time.time()
        prediction_interval = 1.0  # æ¯ç§’é‡æ–°é¢„æµ‹ä¸€æ¬¡
        last_prediction_time = 0
        
        step_count = 0
        
        try:
            while time.time() - start_time < duration:
                step_start = time.time()
                
                # è·å–æœºå™¨äººçŠ¶æ€å’Œå›¾åƒ
                qpos = self.get_robot_state()
                images_dict = self.get_camera_images()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°é¢„æµ‹
                current_time = time.time()
                if (current_time - last_prediction_time > prediction_interval or 
                    self.action_buffer is None):
                    
                    print(f"\nğŸ”„ æ­¥éª¤ {step_count}: é‡æ–°é¢„æµ‹åŠ¨ä½œåºåˆ—...")
                    prediction_start = time.time()
                    
                    try:
                        self.predict_action_sequence(qpos, images_dict)
                        prediction_time = time.time() - prediction_start
                        print(f"   é¢„æµ‹è€—æ—¶: {prediction_time*1000:.1f}ms")
                        print(f"   é¢„æµ‹åºåˆ—é•¿åº¦: {len(self.action_buffer)}")
                        last_prediction_time = current_time
                    except Exception as e:
                        print(f"   âŒ é¢„æµ‹å¤±è´¥: {e}")
                        continue
                
                # è·å–å½“å‰åŠ¨ä½œ
                action = self.get_next_action()
                if action is not None:
                    # å‘é€åŠ¨ä½œåˆ°æœºå™¨äºº
                    self.send_action_to_robot(action)
                    
                    if step_count % 10 == 0:  # æ¯10æ­¥æ‰“å°ä¸€æ¬¡
                        print(f"   æ­¥éª¤ {step_count}: æ‰§è¡ŒåŠ¨ä½œ {action[:3]:.3f}...")
                else:
                    print(f"   âš ï¸  æ­¥éª¤ {step_count}: æ²¡æœ‰å¯ç”¨åŠ¨ä½œ")
                
                # æ§åˆ¶å¾ªç¯é¢‘ç‡
                step_time = time.time() - step_start
                sleep_time = max(0, dt - step_time)
                if sleep_time > 0:
                    time.sleep(sleep_time)
                elif step_time > dt:
                    print(f"   âš ï¸  æ§åˆ¶å¾ªç¯è¶…æ—¶: {step_time*1000:.1f}ms > {dt*1000:.1f}ms")
                
                step_count += 1
                
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ§åˆ¶å¾ªç¯")
        except Exception as e:
            print(f"\nâŒ æ§åˆ¶å¾ªç¯é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        total_time = time.time() - start_time
        avg_frequency = step_count / total_time
        
        print(f"\nğŸ“Š æ§åˆ¶å¾ªç¯å®Œæˆ:")
        print(f"   æ€»æ­¥æ•°: {step_count}")
        print(f"   æ€»æ—¶é—´: {total_time:.1f}s")
        print(f"   å¹³å‡é¢‘ç‡: {avg_frequency:.1f}Hz")
        
    def test_single_prediction(self):
        """æµ‹è¯•å•æ¬¡é¢„æµ‹æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•å•æ¬¡é¢„æµ‹æ€§èƒ½...")
        
        qpos = self.get_robot_state()
        images_dict = self.get_camera_images()
        
        # é¢„çƒ­
        for i in range(3):
            _ = self.inferencer.predict(qpos, images_dict)
        
        # æµ‹è¯•æ€§èƒ½
        times = []
        for i in range(10):
            start_time = time.time()
            actions = self.inferencer.predict(qpos, images_dict)
            end_time = time.time()
            times.append(end_time - start_time)
            
        avg_time = np.mean(times)
        std_time = np.std(times)
        
        print(f"ğŸ“ˆ é¢„æµ‹æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡è€—æ—¶: {avg_time*1000:.1f} Â± {std_time*1000:.1f} ms")
        print(f"   åŠ¨ä½œåºåˆ—é•¿åº¦: {actions.shape[0]}")
        print(f"   ç†è®ºæœ€å¤§é¢‘ç‡: {1/avg_time:.1f} Hz")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='FR3å®æ—¶æ§åˆ¶')
    parser.add_argument('--ckpt_dir', type=str, 
                       default='ckpts/fr3_peg_in_hole_act',
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•')
    parser.add_argument('--duration', type=int, default=30,
                       help='æ§åˆ¶æ—¶é•¿(ç§’)')
    parser.add_argument('--frequency', type=int, default=10,
                       help='æ§åˆ¶é¢‘ç‡(Hz)')
    parser.add_argument('--test_only', action='store_true',
                       help='ä»…æµ‹è¯•æ€§èƒ½ï¼Œä¸è¿è¡Œæ§åˆ¶å¾ªç¯')
    
    args = parser.parse_args()
    
    try:
        controller = FR3RealtimeController(args.ckpt_dir)
        
        if args.test_only:
            controller.test_single_prediction()
        else:
            controller.run_control_loop(args.duration, args.frequency)
            
    except Exception as e:
        print(f"âŒ æ§åˆ¶å™¨å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()