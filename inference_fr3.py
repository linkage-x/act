#!/usr/bin/env python3

import torch
import numpy as np
import pickle
import os
import argparse
from policy import ACTPolicy
from constants import SIM_TASK_CONFIGS
import h5py

class FR3ACTInference:
    def __init__(self, ckpt_dir, task_name='fr3_peg_in_hole_extended'):
        self.task_name = task_name
        self.ckpt_dir = ckpt_dir
        self.task_config = SIM_TASK_CONFIGS[task_name]
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        self.load_dataset_stats()
        
        # åˆå§‹åŒ–ç­–ç•¥
        self.init_policy()
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        self.load_best_policy()
        
    def load_dataset_stats(self):
        """åŠ è½½æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ç”¨äºå½’ä¸€åŒ–"""
        stats_path = os.path.join(self.ckpt_dir, 'dataset_stats.pkl')
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°dataset_stats.pklï¼Œå°è¯•æ‰¾dataset_stats_bac.pkl
        if not os.path.exists(stats_path):
            stats_path = os.path.join(self.ckpt_dir, 'dataset_stats_bac.pkl')
            
        if not os.path.exists(stats_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®é›†ç»Ÿè®¡æ–‡ä»¶: {stats_path}")
            
        with open(stats_path, 'rb') as f:
            self.dataset_stats = pickle.load(f)
            
        print(f"âœ… åŠ è½½æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯: {stats_path}")
        print(f"   - ç»Ÿè®¡ä¿¡æ¯é”®: {list(self.dataset_stats.keys())}")
        
    def init_policy(self):
        """åˆå§‹åŒ–ACTç­–ç•¥"""
        state_dim = self.task_config['state_dim']
        
        # ACTç­–ç•¥å‚æ•° (ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
        policy_config = {
            'lr': 1e-5,
            'num_queries': 100,  # chunk_size
            'kl_weight': 10,
            'hidden_dim': 512,
            'dim_feedforward': 3200,
            'lr_backbone': 1e-5,
            'backbone': 'resnet18',
            'enc_layers': 4,
            'dec_layers': 7,
            'nheads': 8,
            'camera_names': self.task_config['camera_names'],
            'vq': False,
            'vq_class': None,
            'vq_dim': None,
            'action_dim': state_dim,
            'no_encoder': False,
        }
        
        self.policy = ACTPolicy(policy_config)
        self.policy.to(self.device)
        self.policy.eval()
        
        print(f"âœ… ACTç­–ç•¥åˆå§‹åŒ–å®Œæˆ")
        print(f"   - Stateç»´åº¦: {state_dim}")
        print(f"   - Actionå—å¤§å°: {policy_config['num_queries']}")
        print(f"   - ç›¸æœº: {policy_config['camera_names']}")
        
    def load_best_policy(self):
        """åŠ è½½æœ€ä½³è®­ç»ƒæ¨¡å‹"""
        policy_path = os.path.join(self.ckpt_dir, 'policy_best.ckpt')
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°policy_best.ckptï¼Œå°è¯•æ‰¾policy_best_bac.ckpt
        if not os.path.exists(policy_path):
            policy_path = os.path.join(self.ckpt_dir, 'policy_best_bac.ckpt')
            
        if not os.path.exists(policy_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç­–ç•¥æ–‡ä»¶: {policy_path}")
            
        checkpoint = torch.load(policy_path, map_location=self.device)
        self.policy.load_state_dict(checkpoint)
        
        print(f"âœ… åŠ è½½æœ€ä½³ç­–ç•¥æ¨¡å‹: {policy_path}")
        
    def normalize_data(self, data, stats, key):
        """æ•°æ®å½’ä¸€åŒ–"""
        mean = stats[f'{key}_mean']
        std = stats[f'{key}_std']
        return (data - mean) / std
        
    def denormalize_data(self, data, stats, key):
        """æ•°æ®åå½’ä¸€åŒ–"""
        mean = stats[f'{key}_mean']
        std = stats[f'{key}_std']
        return data * std + mean
        
    def preprocess_images(self, images_dict):
        """é¢„å¤„ç†å›¾åƒæ•°æ®"""
        processed_images = {}
        
        for cam_name, image in images_dict.items():
            if cam_name not in self.task_config['camera_names']:
                continue
                
            # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡® (H, W, C) -> (C, H, W)
            if len(image.shape) == 3 and image.shape[-1] == 3:
                image = image.transpose(2, 0, 1)
                
            # å½’ä¸€åŒ–åˆ° [0, 1]
            if image.max() > 1.0:
                image = image.astype(np.float32) / 255.0
                
            # è½¬æ¢ä¸ºtensorå¹¶æ·»åŠ batchç»´åº¦
            image_tensor = torch.from_numpy(image).float().to(self.device)
            if len(image_tensor.shape) == 3:
                image_tensor = image_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
                
            processed_images[cam_name] = image_tensor
            
        return processed_images
        
    def predict(self, qpos, images_dict):
        """
        è¿›è¡ŒåŠ¨ä½œé¢„æµ‹
        
        Args:
            qpos: å½“å‰å…³èŠ‚ä½ç½® (8ç»´åº¦)
            images_dict: ç›¸æœºå›¾åƒå­—å…¸ {'ee_cam': img, 'third_person_cam': img}
            
        Returns:
            predicted_actions: é¢„æµ‹çš„åŠ¨ä½œåºåˆ— (chunk_size, 8)
        """
        with torch.no_grad():
            # é¢„å¤„ç†è¾“å…¥æ•°æ®
            qpos = np.array(qpos)
            if qpos.shape[0] != self.task_config['state_dim']:
                raise ValueError(f"QPosç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.task_config['state_dim']}, å¾—åˆ°{qpos.shape[0]}")
                
            # å½’ä¸€åŒ–qpos
            qpos_normalized = self.normalize_data(qpos, self.dataset_stats, 'qpos')
            qpos_tensor = torch.from_numpy(qpos_normalized).float().to(self.device)
            qpos_tensor = qpos_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            
            # é¢„å¤„ç†å›¾åƒ
            image_tensors = self.preprocess_images(images_dict)
            
            # æ„å»ºè¾“å…¥æ•°æ®
            if len(image_tensors) != len(self.task_config['camera_names']):
                raise ValueError(f"ç›¸æœºæ•°é‡ä¸åŒ¹é…: æœŸæœ›{self.task_config['camera_names']}, å¾—åˆ°{list(image_tensors.keys())}")
                
            # ç­–ç•¥æ¨ç†
            actions = self.policy(qpos_tensor, image_tensors)
            
            # åå½’ä¸€åŒ–åŠ¨ä½œ
            actions_np = actions.cpu().numpy().squeeze(0)  # ç§»é™¤batchç»´åº¦
            actions_denorm = self.denormalize_data(actions_np, self.dataset_stats, 'action')
            
            return actions_denorm
            
    def predict_from_episode(self, episode_path, timestep=0):
        """
        ä»episodeæ–‡ä»¶ä¸­è¯»å–æ•°æ®å¹¶è¿›è¡Œé¢„æµ‹
        
        Args:
            episode_path: HDF5 episodeæ–‡ä»¶è·¯å¾„
            timestep: è¦é¢„æµ‹çš„æ—¶é—´æ­¥
            
        Returns:
            predicted_actions: é¢„æµ‹çš„åŠ¨ä½œåºåˆ—
            ground_truth: çœŸå®åŠ¨ä½œ (ç”¨äºå¯¹æ¯”)
        """
        with h5py.File(episode_path, 'r') as f:
            # è¯»å–æ•°æ®
            qpos = f['observations/qpos'][timestep]
            ee_cam = f['observations/images/ee_cam'][timestep]
            third_person_cam = f['observations/images/third_person_cam'][timestep]
            
            # çœŸå®åŠ¨ä½œ (ç”¨äºå¯¹æ¯”)
            if timestep < f['action'].shape[0]:
                ground_truth = f['action'][timestep]
            else:
                ground_truth = None
                
        # æ„å»ºå›¾åƒå­—å…¸
        images_dict = {
            'ee_cam': ee_cam,
            'third_person_cam': third_person_cam
        }
        
        # è¿›è¡Œé¢„æµ‹
        predicted_actions = self.predict(qpos, images_dict)
        
        return predicted_actions, ground_truth, qpos
        
    def evaluate_episode(self, episode_path, num_steps=10):
        """
        è¯„ä¼°æ•´ä¸ªepisodeçš„é¢„æµ‹æ€§èƒ½
        
        Args:
            episode_path: HDF5 episodeæ–‡ä»¶è·¯å¾„
            num_steps: è¦è¯„ä¼°çš„æ­¥æ•°
        """
        print(f"\nğŸ“Š è¯„ä¼°Episode: {episode_path}")
        
        mse_errors = []
        
        with h5py.File(episode_path, 'r') as f:
            episode_len = min(f['action'].shape[0], num_steps)
            
        for t in range(episode_len):
            pred_actions, gt_action, qpos = self.predict_from_episode(episode_path, t)
            
            if gt_action is not None:
                # è®¡ç®—MSEè¯¯å·® (åªæ¯”è¾ƒç¬¬ä¸€ä¸ªåŠ¨ä½œï¼Œå› ä¸ºchunk_size=100)
                mse = np.mean((pred_actions[0] - gt_action) ** 2)
                mse_errors.append(mse)
                
                if t % 5 == 0:  # æ¯5æ­¥æ‰“å°ä¸€æ¬¡
                    print(f"  æ­¥éª¤ {t:3d}: MSE={mse:.6f}")
                    print(f"    é¢„æµ‹: {pred_actions[0]}")
                    print(f"    çœŸå®: {gt_action}")
                    
        avg_mse = np.mean(mse_errors)
        print(f"\nğŸ“ˆ å¹³å‡MSEè¯¯å·®: {avg_mse:.6f}")
        return avg_mse

def main():
    parser = argparse.ArgumentParser(description='FR3 ACTæ¨¡å‹æ¨ç†')
    parser.add_argument('--ckpt_dir', type=str, required=True,
                       help='æ£€æŸ¥ç‚¹ç›®å½•è·¯å¾„')
    parser.add_argument('--episode_path', type=str, default=None,
                       help='æµ‹è¯•episodeçš„HDF5æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--task_name', type=str, default='fr3_peg_in_hole_extended',
                       help='ä»»åŠ¡åç§°')
    parser.add_argument('--num_steps', type=int, default=20,
                       help='è¯„ä¼°çš„æ­¥æ•°')
    parser.add_argument('--timestep', type=int, default=0,
                       help='å•æ­¥é¢„æµ‹çš„æ—¶é—´æ­¥')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        print("ğŸš€ åˆå§‹åŒ–FR3 ACTæ¨ç†å™¨...")
        inferencer = FR3ACTInference(args.ckpt_dir, args.task_name)
        
        if args.episode_path:
            if os.path.exists(args.episode_path):
                # è¯„ä¼°æŒ‡å®šepisode
                inferencer.evaluate_episode(args.episode_path, args.num_steps)
            else:
                print(f"âŒ Episodeæ–‡ä»¶ä¸å­˜åœ¨: {args.episode_path}")
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šepisodeï¼Œå°è¯•æ‰¾ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
            dataset_dir = inferencer.task_config['dataset_dir']
            test_files = [f for f in os.listdir(dataset_dir) if f.endswith('.hdf5')]
            
            if test_files:
                test_file = os.path.join(dataset_dir, test_files[0])
                print(f"ğŸ¯ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
                inferencer.evaluate_episode(test_file, args.num_steps)
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
                
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()