#!/usr/bin/env python3

import torch
import numpy as np
import yaml
import os
import cv2
import matplotlib.pyplot as plt
from data_augmentation import create_training_augmentation

def test_transforms_augmentation():
    """æµ‹è¯•PyTorch transformså…‰ç…§å¢å¼º"""

    print("ğŸ§ª æµ‹è¯•PyTorch transformså…‰ç…§å¢å¼º...")

    # 1. åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(__file__), 'configs', 'lighting_augmentation.yaml')
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    print(f"âœ… åŠ è½½é…ç½®: {config}")

    # 2. åˆ›å»ºå¢å¼ºå‡½æ•°
    augmentation_fn = create_training_augmentation(config)

    if augmentation_fn is None:
        print("âš ï¸  å¢å¼ºåŠŸèƒ½å·²ç¦ç”¨")
        return True

    # 3. åˆ›å»ºæµ‹è¯•å›¾åƒ (æ¨¡æ‹Ÿç›¸æœºè¾“å…¥)
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²æµ‹è¯•å›¾åƒ
    test_image = create_test_image()

    # è½¬æ¢ä¸ºPyTorch tensoræ ¼å¼ (C, H, W)
    image_tensor = torch.from_numpy(test_image).float() / 255.0
    image_tensor = image_tensor.permute(2, 0, 1)  # HWC -> CHW

    print(f"ğŸ“Š æµ‹è¯•å›¾åƒå½¢çŠ¶: {image_tensor.shape}")
    print(f"ğŸ“Š åƒç´ å€¼èŒƒå›´: [{image_tensor.min():.3f}, {image_tensor.max():.3f}]")

    # 4. åº”ç”¨å¢å¼º
    print("\nğŸ¨ åº”ç”¨å…‰ç…§å¢å¼º...")

    # æµ‹è¯•å•å¼ å›¾åƒ
    augmented_single = augmentation_fn(image_tensor)
    print(f"âœ… å•å¼ å›¾åƒå¢å¼º: {image_tensor.shape} -> {augmented_single.shape}")

    # æµ‹è¯•æ‰¹æ¬¡å›¾åƒ (æ¨¡æ‹Ÿå¤šç›¸æœºè¾“å…¥)
    batch_images = torch.stack([image_tensor, image_tensor, image_tensor], dim=0)  # (3, C, H, W)
    augmented_batch = augmentation_fn(batch_images)
    print(f"âœ… æ‰¹æ¬¡å›¾åƒå¢å¼º: {batch_images.shape} -> {augmented_batch.shape}")

    # 5. éªŒè¯è¾“å‡º
    print("\nğŸ” éªŒè¯å¢å¼ºæ•ˆæœ...")

    # æ£€æŸ¥è¾“å‡ºèŒƒå›´
    assert augmented_single.min() >= 0.0 and augmented_single.max() <= 1.0, "å•å¼ å›¾åƒåƒç´ å€¼è¶…å‡ºèŒƒå›´"
    assert augmented_batch.min() >= 0.0 and augmented_batch.max() <= 1.0, "æ‰¹æ¬¡å›¾åƒåƒç´ å€¼è¶…å‡ºèŒƒå›´"

    # æ£€æŸ¥å½¢çŠ¶ä¿æŒ
    assert augmented_single.shape == image_tensor.shape, "å•å¼ å›¾åƒå½¢çŠ¶æ”¹å˜"
    assert augmented_batch.shape == batch_images.shape, "æ‰¹æ¬¡å›¾åƒå½¢çŠ¶æ”¹å˜"

    print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡")

    # 6. å¯è§†åŒ–æ•ˆæœ (å¯é€‰)
    if True:  # è®¾ä¸ºTrueæŸ¥çœ‹æ•ˆæœ
        visualize_augmentation_effects(image_tensor, augmented_single, augmentation_fn)

    return True

def create_test_image(height=480, width=640):
    """åˆ›å»ºå½©è‰²æµ‹è¯•å›¾åƒ"""
    image = np.zeros((height, width, 3), dtype=np.uint8)

    # åˆ›å»ºæ¸å˜èƒŒæ™¯
    for i in range(height):
        for j in range(width):
            image[i, j, 0] = int(255 * i / height)  # çº¢è‰²æ¸å˜
            image[i, j, 1] = int(255 * j / width)   # ç»¿è‰²æ¸å˜
            image[i, j, 2] = 128                     # è“è‰²å¸¸é‡

    # æ·»åŠ ä¸€äº›å‡ ä½•å½¢çŠ¶
    cv2.rectangle(image, (100, 100), (200, 200), (255, 255, 255), -1)
    cv2.circle(image, (400, 300), 50, (0, 0, 255), -1)
    cv2.line(image, (0, 0), (width, height), (255, 0, 0), 3)

    return image

def visualize_augmentation_effects(original, augmented, augmentation_fn, num_samples=4):
    """å¯è§†åŒ–å¢å¼ºæ•ˆæœ"""
    print("\nğŸ–¼ï¸  ç”Ÿæˆå¯è§†åŒ–æ•ˆæœ...")

    # ç”Ÿæˆå¤šä¸ªå¢å¼ºæ ·æœ¬
    samples = [original]
    for i in range(num_samples):
        sample = augmentation_fn(original)
        samples.append(sample)

    # è½¬æ¢ä¸ºnumpyæ ¼å¼ç”¨äºæ˜¾ç¤º
    samples_np = []
    for sample in samples:
        # CHW -> HWC, [0,1] -> [0,255]
        img_np = (sample.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
        samples_np.append(img_np)

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, len(samples_np), figsize=(15, 3))

    titles = ['åŸå§‹'] + [f'å¢å¼º{i+1}' for i in range(num_samples)]

    for i, (img, title) in enumerate(zip(samples_np, titles)):
        if len(samples_np) == 1:
            ax = axes
        else:
            ax = axes[i]
        ax.imshow(img)
        ax.set_title(title)
        ax.axis('off')

    plt.tight_layout()

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    output_path = '/tmp/lighting_augmentation_test.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
    plt.close()

def performance_test(augmentation_fn, batch_size=8, num_iterations=100):
    """æ€§èƒ½æµ‹è¯•"""
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯• (æ‰¹æ¬¡å¤§å°: {batch_size}, è¿­ä»£æ¬¡æ•°: {num_iterations})...")

    # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
    test_images = torch.randn(batch_size, 3, 480, 640)  # éšæœºå›¾åƒ
    test_images = torch.clamp(test_images * 0.3 + 0.5, 0, 1)  # è§„èŒƒåŒ–åˆ°[0,1]

    import time

    # é¢„çƒ­
    for _ in range(10):
        _ = augmentation_fn(test_images)

    # è®¡æ—¶
    start_time = time.time()
    for _ in range(num_iterations):
        _ = augmentation_fn(test_images)
    end_time = time.time()

    total_time = end_time - start_time
    avg_time = total_time / num_iterations
    fps = batch_size / avg_time

    print(f"ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {avg_time*1000:.2f}ms/æ‰¹æ¬¡")
    print(f"ğŸ“Š å¤„ç†é€Ÿåº¦: {fps:.1f} å›¾åƒ/ç§’")
    print(f"ğŸ“Š æ€»æ—¶é—´: {total_time:.2f}ç§’")

if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    success = test_transforms_augmentation()

    if success:
        print("\nğŸ‰ PyTorch transformså…‰ç…§å¢å¼ºæµ‹è¯•æˆåŠŸ!")

        # å¯é€‰ï¼šè¿è¡Œæ€§èƒ½æµ‹è¯•
        try:
            config_path = os.path.join(os.path.dirname(__file__), 'configs', 'lighting_augmentation.yaml')
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            augmentation_fn = create_training_augmentation(config)
            if augmentation_fn:
                performance_test(augmentation_fn)
        except Exception as e:
            print(f"âš ï¸  æ€§èƒ½æµ‹è¯•è·³è¿‡: {e}")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")
        exit(1)